{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inter: 883636\n",
      "item: 186189\n",
      "user: 749233\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "rating_df = pd.read_csv('/ssd1/holdenhu/Amazon_dataset/Amazon_Fashion/raw/rating_AMAZON_FASHION.csv', header=None)\n",
    "# rating_df = pd.read_csv('/ssd1/holdenhu/feature_dataset/Amazon_Beauty/raw/rating_All_Beauty.csv', sep='\\t')\n",
    "rating_df.columns = ['itemid', 'userid','rating','timestamp']\n",
    "print('inter:',len(rating_df))\n",
    "print('item:',len(set(rating_df['itemid'])))\n",
    "print('user:',len(set(rating_df['userid'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inter: 711838\n",
      "item: 162757\n",
      "user: 608753\n"
     ]
    }
   ],
   "source": [
    "# rating<3的删除\n",
    "rating_df = rating_df[~(rating_df['rating']<3)]\n",
    "print('inter:',len(rating_df))\n",
    "print('item:',len(set(rating_df['itemid'])))\n",
    "print('user:',len(set(rating_df['userid'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711838\n",
      "156149\n",
      "127120\n",
      "115577\n",
      "112499\n",
      "110812\n",
      "110291\n",
      "110015\n",
      "109929\n",
      "109886\n",
      "109876\n",
      "109871\n",
      "109870\n",
      "Finish searching core.\n",
      "inter: 109870\n",
      "item: 13858\n",
      "user: 46365\n"
     ]
    }
   ],
   "source": [
    "# 5-core\n",
    "ITEM_CORE,USER_CORE = 2,2\n",
    "print(len(rating_df))\n",
    "del_item_num, del_user_num = 100,100\n",
    "\n",
    "while del_item_num>0 or del_user_num>0:\n",
    "    # 出现<5次的全部删除\n",
    "    item_count = pd.DataFrame(rating_df['itemid'].value_counts())\n",
    "    item_count.columns = ['nums']\n",
    "    item_count = item_count[item_count['nums'] < ITEM_CORE]\n",
    "    item_delindexs = item_count.index\n",
    "    del_item_num = len(item_delindexs)\n",
    "    # 出现<5次的全部删除\n",
    "    user_count = pd.DataFrame(rating_df['userid'].value_counts())\n",
    "    user_count.columns = ['nums']\n",
    "    user_count = user_count[user_count['nums'] < USER_CORE]\n",
    "    user_delindexs = user_count.index\n",
    "    del_user_num = len(user_delindexs)\n",
    "    if del_item_num==0 and del_user_num==0:\n",
    "        print(\"Finish searching core.\")\n",
    "        break\n",
    "    rating_df = rating_df[~rating_df['itemid'].isin(item_delindexs)]\n",
    "    rating_df = rating_df[~rating_df['userid'].isin(user_delindexs)]\n",
    "    print(len(rating_df))\n",
    "print('inter:',len(rating_df))\n",
    "print('item:',len(set(rating_df['itemid'])))\n",
    "print('user:',len(set(rating_df['userid'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # user-based filter\n",
    "# CORE=3\n",
    "# print(len(rating_df))\n",
    "# del_user_num = 100\n",
    "\n",
    "# # 出现<5次的全部删除\n",
    "# user_count = pd.DataFrame(rating_df['userid'].value_counts())\n",
    "# user_count.columns = ['nums']\n",
    "# user_count = user_count[user_count['nums'] < CORE]\n",
    "# user_delindexs = user_count.index\n",
    "# del_user_num = len(user_delindexs)\n",
    "\n",
    "# rating_df = rating_df[~rating_df['userid'].isin(user_delindexs)]\n",
    "# print(len(rating_df))\n",
    "# print('inter:',len(rating_df))\n",
    "# print('item:',len(set(rating_df['itemid'])))\n",
    "# print('user:',len(set(rating_df['userid'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemid_dict = {} # original item id => new id\n",
    "userid_dict = {} # to save\n",
    "all_item = list(set(rating_df['itemid']))\n",
    "all_user = list(set(rating_df['userid']))\n",
    "for i in all_item:\n",
    "    itemid_dict[i]=len(itemid_dict)+1\n",
    "for u in all_user:\n",
    "    userid_dict[u]=len(userid_dict)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "userid_his = list(rating_df.sort_values(['userid','timestamp'],ascending=True).groupby('userid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46365/46365 [00:05<00:00, 8787.14it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "user_hist_dict = {}\n",
    "for user_record in tqdm(userid_his):\n",
    "    userid = user_record[0]\n",
    "    record = user_record[1]\n",
    "    item_list = [itemid_dict[i] for i in list(record['itemid'])]\n",
    "    t_lit = list(record['timestamp'])\n",
    "    user_hist_dict[userid_dict[userid]] = [(i,t) for i,t in zip(item_list, t_lit)]\n",
    "# 30364: [(12197, 1409011200), (7894, 1430524800), (11612, 1430524800)],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test splition\n",
    "## based on timestamp, 一刀切\n",
    "split_ratio = 0.2\n",
    "t_list = sorted(rating_df['timestamp'])\n",
    "le = len(t_list)\n",
    "split_idx = le - int(le*split_ratio)\n",
    "split_time = t_list[split_idx]\n",
    "\n",
    "all_train_seq, all_test_seq = [],[] # (u, [i0,i1,i2])\n",
    "for u, record in user_hist_dict.items():\n",
    "    train_data, test_data = [], []\n",
    "    for i,t in record:\n",
    "        if t<= split_time:\n",
    "            train_data.append(i)\n",
    "        else:\n",
    "            test_data.append(i)\n",
    "    if len(train_data)>0:\n",
    "        all_train_seq.append((u,train_data))\n",
    "    if len(test_data)>0:\n",
    "        all_test_seq.append((u,train_data,test_data))\n",
    "\n",
    "## leave-one-out [TODO]\n",
    "## user-specific ratio-based [TODO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) test.txt; (4) train.txt; data[0][idx]=>sequence, data[0][idx]=>label\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "def process_train_seq(train_seq): # input: [u, (i0,i1,i2)]\n",
    "    out_seqs = []\n",
    "    labs = []\n",
    "    for u,seq in train_seq: # TO: I dont use the user ID for now\n",
    "        for i in range(1, len(seq)):\n",
    "            tar = seq[-i]\n",
    "            labs += [tar]\n",
    "            out_seqs += [seq[:-i]]\n",
    "    return out_seqs, labs\n",
    "\n",
    "def process_test_seq(test_seq): # input: [u, (i0,i1,i2)]\n",
    "    out_seqs = []\n",
    "    labs = []\n",
    "    for u, train_seq, seq in test_seq: # TO: I dont use the user ID for now\n",
    "        for i in range(1, len(seq)):\n",
    "            tar = seq[-i]\n",
    "            labs += [tar]\n",
    "            out_seqs += [train_seq+seq[:-i]]\n",
    "    return out_seqs, labs\n",
    "\n",
    "tr_seqs, tr_labs = process_train_seq(all_train_seq)\n",
    "te_seqs, te_labs = process_test_seq(all_test_seq)\n",
    "tra = (tr_seqs, tr_labs)\n",
    "tes = (te_seqs, te_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(itemid_dict, open('/ssd1/holdenhu/Amazon_dataset/Amazon_Fashion/itemid_dict.txt','wb'))\n",
    "pickle.dump(userid_dict, open('/ssd1/holdenhu/Amazon_dataset/Amazon_Fashion/userid_dict.txt','wb'))\n",
    "pickle.dump(all_test_seq, open('/ssd1/holdenhu/Amazon_dataset/Amazon_Fashion/all_test_seq.txt','wb'))\n",
    "pickle.dump(all_train_seq, open('/ssd1/holdenhu/Amazon_dataset/Amazon_Fashion/all_train_seq.txt','wb'))\n",
    "\n",
    "pickle.dump(tra, open('/ssd1/holdenhu/Amazon_dataset/Amazon_Fashion/train.txt','wb'))\n",
    "pickle.dump(tes, open('/ssd1/holdenhu/Amazon_dataset/Amazon_Fashion/test.txt','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13858 20 20\n"
     ]
    }
   ],
   "source": [
    "################ New thread\n",
    "# train_k.txt, test_k.txt\n",
    "import pickle\n",
    "cluster_num=20\n",
    "k=1\n",
    "\n",
    "asin_topic_dict = pickle.load(open('/ssd1/holdenhu/Amazon_dataset/Amazon_Fashion/processed/text/asin_clusters{}_dict.pickle'.format(cluster_num),'rb'))\n",
    "asin_image_dict = pickle.load(open('/ssd1/holdenhu/Amazon_dataset/Amazon_Fashion/processed/image/image_cluster{}_dict.pickle'.format(cluster_num),'rb'))\n",
    "itemid_dict = pickle.load(open('/ssd1/holdenhu/Amazon_dataset/Amazon_Fashion/itemid_dict.txt','rb'))\n",
    "train = pickle.load(open('/ssd1/holdenhu/Amazon_dataset/Amazon_Fashion/train.txt','rb'))\n",
    "test = pickle.load(open('/ssd1/holdenhu/Amazon_dataset/Amazon_Fashion/test.txt','rb'))\n",
    "node_num = len(itemid_dict.values())+1 # and 0<pad>\n",
    "image_num = max(asin_image_dict.values())+1\n",
    "text_num = max(asin_topic_dict.values())+1\n",
    "print(len(itemid_dict.values()), image_num, text_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_item_dict = {v: k for k, v in itemid_dict.items()}\n",
    "\n",
    "def process_vl(data):\n",
    "    seqs = data[0]\n",
    "    text_seqs, image_seqs = [],[]\n",
    "    for seq in seqs:\n",
    "        image_seq = []\n",
    "        text_seq = []\n",
    "        for i in seq:\n",
    "            itemid = reverse_item_dict[i]\n",
    "            if itemid in asin_image_dict:\n",
    "                image_c = [asin_image_dict[itemid]+node_num]\n",
    "            else:\n",
    "                image_c = []\n",
    "            image_seq.append(image_c)\n",
    "            \n",
    "            if itemid in asin_topic_dict:\n",
    "                text_c = [asin_topic_dict[itemid]+node_num+image_num]\n",
    "            else:\n",
    "                text_c = []\n",
    "            text_seq.append(text_c)\n",
    "        text_seqs.append(text_seq)\n",
    "        image_seqs.append(image_seq)\n",
    "    return text_seqs, image_seqs\n",
    "tra_text_seqs, tra_image_seqs = process_vl(train)\n",
    "tes_text_seqs, tes_image_seqs = process_vl(test)\n",
    "\n",
    "pickle.dump([train[0], tra_text_seqs, tra_image_seqs, train[1]], open('/ssd1/holdenhu/Amazon_dataset/Amazon_Fashion/train_c{}_k{}.txt'.format(cluster_num,k),'wb'))\n",
    "pickle.dump([test[0], tes_text_seqs, tes_image_seqs, test[1]], open('/ssd1/holdenhu/Amazon_dataset/Amazon_Fashion/test_c{}_k{}.txt'.format(cluster_num,k),'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "_ = pd.read_csv('/ssd1/holdenhu/Amazon_dataset/Amazon_Fashion/raw/rating_AMAZON_FASHION.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7106116521</th>\n",
       "      <th>A1D4G1SNUZWQOT</th>\n",
       "      <th>5.0</th>\n",
       "      <th>1413763200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>A3DDWDH9PX2YX2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1411862400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>A2MWC41EW7XL15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1408924800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>A2UH2QQ275NV45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1408838400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>A89F3LQADZBS5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1406419200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>A29HLOUW0NS0EH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1405728000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   7106116521  A1D4G1SNUZWQOT  5.0  1413763200\n",
       "0  7106116521  A3DDWDH9PX2YX2  2.0  1411862400\n",
       "1  7106116521  A2MWC41EW7XL15  4.0  1408924800\n",
       "2  7106116521  A2UH2QQ275NV45  2.0  1408838400\n",
       "3  7106116521   A89F3LQADZBS5  3.0  1406419200\n",
       "4  7106116521  A29HLOUW0NS0EH  5.0  1405728000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/holdenhu/miniconda3/envs/recbole/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  itemid  rating  timestamp\n",
       "0       1    1193       5  978300760\n",
       "1       1     661       3  978302109\n",
       "2       1     914       3  978301968\n",
       "3       1    3408       4  978300275\n",
       "4       1    2355       5  978824291"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df = pd.read_csv('/ssd1/holdenhu/ML_dataset/ml-1m/raw/ratings.dat',sep='::',header=None)\n",
    "rating_df.columns = ['userid', 'itemid','rating','timestamp']\n",
    "# UserID::MovieID::Rating::Timestamp\n",
    "rating_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('recbole')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b86f3a1c461bf87e9457c32697f800e50c3f11546faa77218a60ce1650cf690e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
